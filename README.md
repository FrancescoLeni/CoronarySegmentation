# CoronarySegmentation

This repository contains code developed for training and evaluating deep learning models for **coronary artery segmentation** in CT angiography (CTCA), using the publicly available [ASOCA dataset](https://asoca.grand-challenge.org/). The approach integrates **centerline priors** into the learning process, with the goal of assessing whether this anatomical guidance can improve segmentation performanceâ€”particularly in challenging cases involving complex vessel morphology or pathology.

The pipeline supports full-volume preprocessing, 2D and 3D segmentation workflows, and is designed for flexibility in model architecture.

## ğŸ§  Centerline Prior

To enhance segmentation performance and encourage anatomical awareness, this project integrates **coronary centerline information** into the model training pipeline in two key ways: intelligent cropping and attention-based input encoding.

<p align="center">
  <img src="repo_data/cropping.gif" alt="cropping" width="320"/>
  <img src="repo_data/fix%20grid.gif" alt="grid" width="320"/>
</p>


---

### ğŸ—‚ï¸ ROI Cropping

Instead of relying on traditional fixed-grid slicing strategies, we leverage the **coronary centerline** to identify the most informative regions within each CT slice.

- We cluster the centerline points along the axial volume using spatial clustering (e.g., k-means), obtaining centroids that represent high-content regions along the vessels.
- Each 2D slice is then cropped around these **centerline-derived centroids**, rather than using arbitrary or equidistant grid crops.
- This strategy **maximizes anatomical relevance per crop**, enabling the model to focus on coronary-rich regions rather than large backgrounds or irrelevant structures.
- As a result, we achieved **comparable or superior performance using less than half the training data**, thanks to more efficient data sampling guided by anatomical priors.

---

### ğŸ¯ Attention

To further emphasize coronary structures during training, we introduce a form of **spatial attention** by modifying the input representation:

- Each original grayscale CT slice is augmented with a second channel.
- In this additional channel, the pixels belonging to the **centerline mask** are artificially enhanced (brightened) to guide the modelâ€™s focus.
- This dual-channel input allows the network to better **attend to the vascular structures**, particularly in ambiguous or low-contrast regions, without modifying the original image intensities.

Together, these centerline-driven strategies inject prior anatomical knowledge into the training process, resulting in more accurate, focused, and data-efficient coronary segmentation.

---

## ğŸ§  Model Architecture

This work explores both **2D** and **3D U-Net architectures** for coronary artery segmentation. The goal was to determine whether volumetric context (via 3D convolutions) and anatomically-aware cropping could enhance segmentation performance on the ASOCA dataset.

- **2D U-Net**: Applied slice-by-slice with or without centerline-guided cropping.
- **3D U-Net**: Processes volumetric patches, enabling the model to learn spatial continuity across adjacent slices.

Both models were trained under two different input sampling strategies:
- **Grid**: Traditional uniform slicing across the volume.
- **Crop**: Centerline-guided region-of-interest cropping (see [Centerline Prior](#-centerline-prior)).

### ğŸ”¬ Key Findings

The **3D U-Net architecture** combined with **centerline-guided cropping** achieved the best overall performance across all evaluated metrics. This supports the hypothesis that anatomical priors and 3D spatial context are beneficial for fine-grained vessel segmentation.

---

### ğŸ“Š Quantitative Results
## ğŸ“Š Quantitative Results

| Metric     | 3D U-Net + Crop | 3D U-Net + Grid |
|------------|------------------|------------------|
| **Dice**        | **0.87**          | 0.80             |
| **Accuracy**    | **0.94**          | 0.92             |
| **Precision**   | **0.84**          | 0.83             |
| **Recall**      | **0.94**          | 0.92             |

---

## ğŸ¥ Qualitative Results

<p align="center">
  <img src="repo_data/3d%20result_pred.gif" alt="3D U-Net + Crop" width="400" />
  <img src="repo_data/3d%20result_gt.gif" alt="3D U-Net + Grid" width="400" />
</p>

> ğŸ“Œ All values are averaged across the test set using 3D predictions with post-processing.

---


## âš™ï¸ Requirements & Setup

To get started, clone the repository and set up your environment using one of the following options:

### ğŸ” 1. Clone the Repository

```
git clone https://github.com/FrancescoLeni/CoronarySegmentation.git
cd CoronarySegmentation
```

```
pip -r install requirements.txt
```





